{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLOQDOpq9s9kVQxd9nnc2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazasuny/text-preprocessing-practice/blob/main/Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZwXi23oBStZ",
        "outputId": "99b279fd-00d8-4a7e-9045-338cfeece5da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\n",
            "Teks setelah diubah menjadi lowercase: ini adalah contoh teks yang akan dikonversi menjadi lowercase.\n"
          ]
        }
      ],
      "source": [
        "# Contoh teks\n",
        "teks_asli = \"Ini Adalah Contoh Teks yang Akan Dikonversi Menjadi Lowercase.\"\n",
        "\n",
        "# Mengubah teks menjadi lowercase\n",
        "teks_lowercase = teks_asli.lower()\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah diubah menjadi lowercase:\", teks_lowercase)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghapus angka dari teks\n",
        "def hapus_angka(teks):\n",
        "    teks_tanpa_angka = ''.join([char for char in teks if not char.isdigit()])\n",
        "    return teks_tanpa_angka\n",
        "\n",
        "# Contoh teks dengan angka\n",
        "teks_dengan_angka = \"Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka\n",
        "teks_tanpa_angka = hapus_angka(teks_dengan_angka)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks dengan angka:\", teks_dengan_angka)\n",
        "print(\"Teks tanpa angka:\", teks_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSUF3rA0BcH-",
        "outputId": "d218a9af-7098-47f4-baa4-ff6de157fe5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks dengan angka: Ini adalah contoh teks dengan angka 12345 yang akan dihapus.\n",
            "Teks tanpa angka: Ini adalah contoh teks dengan angka  yang akan dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def hapus_angka_tidak_relevan(teks):\n",
        "    # Menggunakan regex untuk mengidentifikasi dan menghapus angka yang tidak relevan\n",
        "    # Pola untuk mengenali angka yang harus dihapus, termasuk nomor rumah dan nomor telepon\n",
        "    pola_angka_tidak_relevan = r\"\\b(?:\\d{1,3}[-\\.\\s]?)?(?:\\d{3}[-\\.\\s]?)?\\d{4,}\\b\"\n",
        "    hasil = re.sub(pola_angka_tidak_relevan, \"\", teks)\n",
        "    return hasil.strip()\n",
        "\n",
        "# Contoh kalimat dengan angka\n",
        "kalimat = \"Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\"\n",
        "\n",
        "# Memanggil fungsi untuk menghapus angka tidak relevan\n",
        "hasil_tanpa_angka = hapus_angka_tidak_relevan(kalimat)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Kalimat dengan angka:\", kalimat)\n",
        "print(\"Kalimat tanpa angka tidak relevan:\", hasil_tanpa_angka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHPmkGydB5PH",
        "outputId": "0ed522d4-f5b5-4f27-98a9-906cf88e62eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kalimat dengan angka: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi 081234567890 untuk informasi lebih lanjut.\n",
            "Kalimat tanpa angka tidak relevan: Di sini ada 3 nomor rumah yaitu  123, 456, dan 789. Silakan hubungi  untuk informasi lebih lanjut.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Membuat set yang berisi semua tanda baca\n",
        "    punctuation_set = set(string.punctuation)\n",
        "\n",
        "    # Menghapus tanda baca dari teks\n",
        "    text_without_punctuation = ''.join(char for char in text if char not in punctuation_set)\n",
        "\n",
        "    return text_without_punctuation\n",
        "\n",
        "# Contoh teks dengan tanda baca\n",
        "teks_asli = \"Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\"\n",
        "\n",
        "# Menghapus tanda baca dari teks\n",
        "teks_tanpa_tanda_baca = remove_punctuation(teks_asli)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Teks asli:\", teks_asli)\n",
        "print(\"Teks setelah menghapus tanda baca:\", teks_tanpa_tanda_baca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9JkpyQBCS9l",
        "outputId": "72cddccc-f14c-4737-b777-64363bba3e9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Ini adalah contoh teks, dengan tanda baca! Contoh ini, digunakan? untuk demonstrasi.\n",
            "Teks setelah menghapus tanda baca: Ini adalah contoh teks dengan tanda baca Contoh ini digunakan untuk demonstrasi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks = \"   Ini adalah contoh kalimat dengan spasi di awal dan akhir.    \"\n",
        "teks_setelah_strip = teks.strip()\n",
        "print(teks_setelah_strip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgizbA2qC2KF",
        "outputId": "54f0cd9c-efa8-4ceb-c9a4-238c97f9a47d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ini adalah contoh kalimat dengan spasi di awal dan akhir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks_dengan_whitespace = \"Ini adalah    contoh kalimat    dengan spasi    di dalamnya.\"\n",
        "teks_tanpa_whitespace = teks_dengan_whitespace.replace(\" \", \"\")\n",
        "print(teks_tanpa_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-sYvanUC3FQ",
        "outputId": "819fd711-1a9b-42ac-afee-300ac1361b9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniadalahcontohkalimatdenganspasididalamnya.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download korpus stopwords bahasa Indonesia dari NLTK jika belum terunduh\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')  # Untuk tokenisasi kata\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Ambil daftar stopwords bahasa Indonesia dari NLTK\n",
        "stopwords_indonesia = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_indonesia]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords NLTK:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YotEC7rsC7zs",
        "outputId": "92415ce3-d811-4d9f-adf6-9a8b6f644b9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords NLTK: Perekonomian Indonesia pertumbuhan membanggakan .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Sastrawi library if not already installed\n",
        "!pip install Sastrawi\n",
        "\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Inisialisasi objek StopWordRemover dari Sastrawi\n",
        "factory = StopWordRemoverFactory()\n",
        "stopwords_sastrawi = factory.get_stop_words()\n",
        "\n",
        "teks = \"Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\"\n",
        "\n",
        "# Tokenisasi teks menjadi kata-kata\n",
        "tokens_kata = word_tokenize(teks)\n",
        "\n",
        "# Filtering kata-kata dengan menghapus stopwords Sastrawi\n",
        "kata_penting = [kata for kata in tokens_kata if kata.lower() not in stopwords_sastrawi]\n",
        "\n",
        "# Gabungkan kata-kata penting kembali menjadi teks\n",
        "teks_tanpa_stopwords = ' '.join(kata_penting)\n",
        "\n",
        "print(\"Teks asli:\", teks)\n",
        "print(\"Teks setelah filtering stopwords Sastrawi:\", teks_tanpa_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hNluC4ID0Hq",
        "outputId": "4a2548b8-341d-44de-8f5f-6a2169801a6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Teks asli: Perekonomian Indonesia sedang dalam pertumbuhan yang membanggakan.\n",
            "Teks setelah filtering stopwords Sastrawi: Perekonomian Indonesia sedang pertumbuhan membanggakan .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZING\n"
      ],
      "metadata": {
        "id": "izGAa6_kGO4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Ini adalah contoh tokenisasi kata dalam pemrosesan teks kata.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT8q_pF2F_TE",
        "outputId": "15dab645-f264-487e-9d03-6324b4649ff9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'kata', 'dalam', 'pemrosesan', 'teks', 'kata', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"Ini adalah contoh tokenisasi kalimat. Apakah ini kalimat kedua? Ya, ini kalimat ketiga!\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k83K1cVgGcWJ",
        "outputId": "d8b3e4a6-5280-49de-bfb8-f92c4a83b338"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini adalah contoh tokenisasi kalimat.', 'Apakah ini kalimat kedua?', 'Ya, ini kalimat ketiga!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "# Misalkan kita ingin memisahkan frasa berdasarkan tanda baca koma (,)\n",
        "text = \"Pemrosesan teks adalah cabang ilmu komputer yang berfokus pada pengolahan teks dan dokumen.\"\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "phrases = tokenizer.tokenize(text)\n",
        "print(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB6dDOhFGfDX",
        "outputId": "0c295511-83d2-408a-ea5f-d5c8803ed41f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pemrosesan', 'teks', 'adalah', 'cabang', 'ilmu', 'komputer', 'yang', 'berfokus', 'pada', 'pengolahan', 'teks', 'dan', 'dokumen', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh aturan tokenisasi khusus untuk tokenisasi kata dalam bahasa Indonesia\n",
        "import re\n",
        "\n",
        "text = \"Pertama, kita perlu menyiapkan bahan-bahan yang diperlukan.\"\n",
        "tokens = re.findall(r'\\w+|\\d+', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWdorCvKHC8k",
        "outputId": "04bf6b5b-9594-401a-e7b7-1b7e7fb1f293"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pertama', 'kita', 'perlu', 'menyiapkan', 'bahan', 'bahan', 'yang', 'diperlukan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Misalnya menggunakan spasi sebagai pemisah kata\n",
        "text = \"Ini adalah contoh tokenisasi berbasis model.\"\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFzl2cM9HDvy",
        "outputId": "f35ade9f-3eb4-4386-de2c-6e848fcd421b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ini', 'adalah', 'contoh', 'tokenisasi', 'berbasis', 'model.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Inisialisasi stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"running\", \"runs\", \"runner\", \"ran\", \"easily\", \"fairness\", \"better\", \"best\", \"cats\", \"cacti\", \"geese\", \"rocks\", \"oxen\"]\n",
        "\n",
        "# Melakukan stemming pada setiap kata\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Kata asli: {word}, Kata setelah stemming: {stemmed_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb-lR6EXHL6W",
        "outputId": "38b65182-31fe-46ab-8cf3-92ff2f758a94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: running, Kata setelah stemming: run\n",
            "Kata asli: runs, Kata setelah stemming: run\n",
            "Kata asli: runner, Kata setelah stemming: runner\n",
            "Kata asli: ran, Kata setelah stemming: ran\n",
            "Kata asli: easily, Kata setelah stemming: easili\n",
            "Kata asli: fairness, Kata setelah stemming: fair\n",
            "Kata asli: better, Kata setelah stemming: better\n",
            "Kata asli: best, Kata setelah stemming: best\n",
            "Kata asli: cats, Kata setelah stemming: cat\n",
            "Kata asli: cacti, Kata setelah stemming: cacti\n",
            "Kata asli: geese, Kata setelah stemming: gees\n",
            "Kata asli: rocks, Kata setelah stemming: rock\n",
            "Kata asli: oxen, Kata setelah stemming: oxen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download wordnet jika belum di-download\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Inisialisasi lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Kata-kata asli\n",
        "words = [\"Run\", \"Cat\", \"Good\", \"Goose\", \"Rock\", \"City\", \"Big\", \"Happy\", \"Run\", \"Sleep\"]\n",
        "\n",
        "# Melakukan lematisasi pada setiap kata\n",
        "for word in words:\n",
        "    lemma_word = lemmatizer.lemmatize(word.lower())  # Mengonversi ke huruf kecil untuk memastikan pemrosesan yang konsisten\n",
        "    print(f\"Kata asli: {word}, Kata setelah lematisasi: {lemma_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3gygVw2IJqj",
        "outputId": "eb7ca595-a26b-4c6f-b667-db2f57cde1a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kata asli: Run, Kata setelah lematisasi: run\n",
            "Kata asli: Cat, Kata setelah lematisasi: cat\n",
            "Kata asli: Good, Kata setelah lematisasi: good\n",
            "Kata asli: Goose, Kata setelah lematisasi: goose\n",
            "Kata asli: Rock, Kata setelah lematisasi: rock\n",
            "Kata asli: City, Kata setelah lematisasi: city\n",
            "Kata asli: Big, Kata setelah lematisasi: big\n",
            "Kata asli: Happy, Kata setelah lematisasi: happy\n",
            "Kata asli: Run, Kata setelah lematisasi: run\n",
            "Kata asli: Sleep, Kata setelah lematisasi: sleep\n"
          ]
        }
      ]
    }
  ]
}